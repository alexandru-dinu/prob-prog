{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO, TraceEnum_ELBO, config_enumerate, infer_discrete\n",
    "pyro.enable_validation(True)\n",
    "\n",
    "import torch as T\n",
    "import torch.optim as O\n",
    "import torch.distributions.constraints as constraints\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from bagoftools.plotting import stem_hist\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(n, i, j, do_print=True):\n",
    "    \n",
    "    def _f():\n",
    "        m = 2**n\n",
    "        x = pyro.sample(\"x\", dist.Categorical(T.ones(m)))\n",
    "        pyro.sample(\"obs\", dist.Bernoulli(1.0),\n",
    "                    obs=((x == i) | (x == j)).float())\n",
    "        if do_print:\n",
    "            print('model x = {}'.format(x))\n",
    "        return x\n",
    "    \n",
    "    return _f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.clear_param_store()\n",
    "\n",
    "prog = f(6, 1, 10, do_print=False)\n",
    "posterior = pyro.infer.Importance(prog, num_samples=10000)\n",
    "marginal = pyro.infer.EmpiricalMarginal(posterior.run(), sites=['x'])\n",
    "\n",
    "x = [marginal().item() for _ in range(1_000)]\n",
    "stem_hist(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = f(3, 0, 1, do_print=True)\n",
    "guide = f(3, 0, 1, do_print=True)\n",
    "\n",
    "elbo = TraceEnum_ELBO(max_plate_nesting=0)\n",
    "elbo.loss(model, config_enumerate(guide, \"parallel\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elbo.enumerate_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = lambda: dict(pyro.get_param_store().items())\n",
    "\n",
    "def hist(xs, bins=64, xlim=None):\n",
    "    plt.figure(figsize=(14,4))\n",
    "    _ = plt.hist(xs, bins=bins, density=True, color='c')\n",
    "    \n",
    "    if xlim is not None:\n",
    "        plt.xlim(xlim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dist.Normal(0, 1)\n",
    "p = lambda x: d.log_prob(T.tensor(x)).exp().item()\n",
    "\n",
    "p(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(guess):\n",
    "    weight = pyro.sample('weight', dist.Normal(guess, 1.0))\n",
    "    return pyro.sample('measurement', dist.Normal(weight, 0.75))\n",
    "\n",
    "conditioned_scale = pyro.condition(scale, data={'measurement': 9.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equivalent to conditioned_scale above\n",
    "def scale_obs(guess):\n",
    "    weight = pyro.sample('weight', dist.Normal(guess, 1.))\n",
    "     # here we condition on measurement == 9.5\n",
    "    return pyro.sample('measurement', dist.Normal(weight, 0.75), obs=9.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# both will be equal to the obs value of `measurement`, for any input `guess`\n",
    "conditioned_scale(guess=0), scale_obs(guess=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pyro.condition(data={'z': 1.0})\n",
    "def gauss():\n",
    "    z = pyro.sample('z', dist.Normal(0, 1))\n",
    "    return z\n",
    "\n",
    "gauss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models and Inference\n",
    "**Q:** how are vars involved / inter-related in a model (since they have a name)?\n",
    "\n",
    "**A:** they are stored in `ParamStore` and are used during optimization to model distribution paramters.\n",
    "\n",
    "---\n",
    "\n",
    "- `weather()` specifies a joint probability distribution over two named random variables: `cloudy` and `temp`\n",
    "- it defines a probabilistic model that we can reason about\n",
    "- e.g. if I observe a temperature of 70 degrees, how likely is it to be cloudy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather():\n",
    "    cloudy = pyro.sample('cloudy', dist.Bernoulli(0.3))\n",
    "    cloudy = 'cloudy' if cloudy.item() == 1.0 else 'sunny'\n",
    "    mean_temp = {'cloudy': 55.0, 'sunny': 75.0}[cloudy]\n",
    "    scale_temp = {'cloudy': 10.0, 'sunny': 15.0}[cloudy]\n",
    "    temp = pyro.sample('temp', dist.Normal(mean_temp, scale_temp))\n",
    "    return cloudy, temp.item()\n",
    "\n",
    "weather()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Docs example\n",
    "\n",
    "If `y` is observed to be 9.5,\n",
    "then find `a,b` for `x ~ N(a, b)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose we observe that the measurement of an object was 9.5 lbs. \n",
    "# What would have we guessed if we tried to guess itâ€™s weight first?\n",
    "# i.e. compute P(x | y = 9.5)\n",
    "\n",
    "def model(loc):\n",
    "    x = pyro.sample('x', dist.Normal(loc, 1.0))\n",
    "    y = pyro.sample('y', dist.Normal(x, 0.75))\n",
    "    return y\n",
    "\n",
    "conditioned_model = pyro.condition(model, data={'y': T.tensor(9.5)})\n",
    "\n",
    "def guide(loc):\n",
    "    a = pyro.param('a', T.tensor(loc))\n",
    "    b = pyro.param('b', T.tensor(1.0), constraint=constraints.positive)\n",
    "    x = pyro.sample('x', dist.Normal(a, b))\n",
    "    return x\n",
    "\n",
    "pyro.clear_param_store()\n",
    "svi = pyro.infer.SVI(model=conditioned_model,\n",
    "                     guide=guide,\n",
    "                     optim=pyro.optim.SGD({'lr': 0.001, 'momentum': 0.1}),\n",
    "                     loss=pyro.infer.Trace_ELBO())\n",
    "\n",
    "loc_prior = 8.5\n",
    "losses, a, b  = [], [], []\n",
    "num_steps = 5000\n",
    "for t in tqdm(range(num_steps)):\n",
    "    losses.append(svi.step(loc_prior))\n",
    "    a.append(pyro.param('a').item())\n",
    "    b.append(pyro.param('b').item())\n",
    "\n",
    "print('a = ', pyro.param('a').item())\n",
    "print('b = ', pyro.param('b').item())\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.title('ELBO')\n",
    "plt.xlabel('step')\n",
    "plt.ylabel('loss');\n",
    "plt.figure()\n",
    "plt.plot(a)\n",
    "plt.figure()\n",
    "plt.plot(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pyro.param('a').item()\n",
    "b = pyro.param('b').item()\n",
    "\n",
    "def f_():\n",
    "    x = pyro.sample('x', dist.Normal(a, b))\n",
    "    y = pyro.sample('y', dist.Normal(x, 0.75))\n",
    "    return y\n",
    "\n",
    "out = [f_() for _ in range(50000)]\n",
    "hist(out, bins=96)\n",
    "plt.plot([9.5]*14, np.linspace(0, 0.7, 14), c='r', linewidth=3)\n",
    "plt.plot([a]*14, np.linspace(0, 0.7, 14), c='m', linewidth=3)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate `observe`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rejector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wrapper(dist.Rejector):\n",
    "    def __init__(self, underlying, log_accept, log_scale):    \n",
    "        super(Wrapper, self).__init__(underlying, log_accept, log_scale)\n",
    "\n",
    "\n",
    "underlying = dist.Normal(0, 1)\n",
    "\n",
    "x0 = T.tensor(0.0)\n",
    "\n",
    "# this actually implements the predicate\n",
    "log_accept = lambda x: (x > x0).float().log()\n",
    "\n",
    "# CDF of predicate valid area: P(X > x) = 1 - P(X <= x)\n",
    "log_scale = 1 - underlying.cdf(x0).log()\n",
    "\n",
    "w = Wrapper(underlying, log_accept, log_scale)\n",
    "xs = [pyro.sample('x', w) for _ in range(10000)]\n",
    "\n",
    "plt.figure(figsize=(14, 4))\n",
    "_, bins, _ = plt.hist(xs, bins=32, density=True, color='c')\n",
    "plt.xlim([-3, 3])\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importance sampling\n",
    "- we want to find the posterior $\\left( x | y \\sim \\text{Bernoulli}(1) \\right)$\n",
    "- Bernoulli's success rate controls the predicate compliance\n",
    "- `model()` gives $P(y | x)$\n",
    "- $P(x|y) = P(y|x) \\cdot P(x) \\ / \\ P(y)$\n",
    "\n",
    "#### Observations\n",
    "- `Empirical` (therefore `marginal`) does not have a `cdf`\n",
    "- support = samples from posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicates\n",
    "eq     = lambda a, b: float(np.isclose(a, b, atol=1e-3))\n",
    "eq_any = lambda x, xs: T.tensor(any(map(lambda a: eq(a, x), xs))).float()\n",
    "gt     = lambda x, y: (x > y).float()\n",
    "lt     = lambda x, y: (x < y).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    \"\"\"\n",
    "    s = 1\n",
    "    when (x <= 0) -> y: 1-s\n",
    "    when (x  > 0) -> y: s\n",
    "    \n",
    "    p(x > 0) ~ Bernoulli(s)\n",
    "    \"\"\"\n",
    "#     1. observe(x > 0)\n",
    "    x = pyro.sample('x', dist.Normal(0, 1))\n",
    "    y = pyro.sample('y', dist.Bernoulli(1.0), obs=gt(x, 0))\n",
    "    return y\n",
    "    \n",
    "#     2. obtain z = x + y (choosing a good prior)\n",
    "#     x = pyro.sample('x', dist.Normal(1,1))\n",
    "#     y = pyro.sample('y', dist.Normal(1,1))\n",
    "#     z = pyro.sample('z', dist.Normal(1.5,1), obs=(x+y))\n",
    "#     return z\n",
    "\n",
    "#     3. y < x\n",
    "#     x = pyro.sample('x', dist.Uniform(0, 1))\n",
    "#     y = pyro.sample('y', dist.Uniform(0, 1))\n",
    "#     z = pyro.sample('z', dist.Bernoulli(1.0), obs=lt(y, x))\n",
    "#     return z\n",
    "\n",
    "N = 5000\n",
    "\n",
    "# perform posterior inference by importance sampling\n",
    "posterior = pyro.infer.Importance(model, num_samples=N)\n",
    "\n",
    "# construct marginal distribution\n",
    "marginal  = pyro.infer.EmpiricalMarginal(posterior.run(), sites=['x'])\n",
    "\n",
    "samples = [marginal.sample() for _ in range(2*N)]\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.hist(samples, range=[-4, 4], bins=64, color='c', label='marginal', density=True, stacked=True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = posterior.run()\n",
    "\n",
    "for i, (tr, log_weight) in enumerate(zip(xs.exec_traces, xs.log_weights)):\n",
    "    if i == 10: break\n",
    "    x = tr.nodes['x']['value'].item()\n",
    "    y = log_weight.exp().item()\n",
    "    print(f'{x:8.5f}: {y:7.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "P(x > 0) &= \\frac{1}{\\texttt{xs[xs > 0].size}} \\\\\n",
    "P(x \\leq 0) &= 0\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = lambda x: marginal.log_prob(T.tensor([x])).exp()\n",
    "\n",
    "xs = np.array([x for x in marginal.enumerate_support()])\n",
    "ps = np.array([p(x) for x in xs])\n",
    "\n",
    "p_ = 1/xs[xs>0].size\n",
    "print(f'P(x > 0) = {p_:9.7f}')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(xs, ps, s=1, c='c')\n",
    "plt.plot([xs.min(), xs.max()], [p_] * 2, linewidth=1, c='b', alpha=0.5)\n",
    "\n",
    "# step prob: \n",
    "# p(x  > 0) = 1 / xs[xs > 0].size \n",
    "# p(x <= 0) = 0\n",
    "\n",
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
